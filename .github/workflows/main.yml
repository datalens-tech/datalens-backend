name: main

on:
  push:
    paths:
      - lib/**
      - utils/**
      - ops/ci/**
      - '.github/workflows/main.yml'
  workflow_dispatch:
    inputs:
      test_targets:
        default: ""
        description: "Comma separated list to run pytest on, e.g.: `lib/bi_constants,lib/bi_utils`. "
      run_mypy:
        type: boolean
        default: false
        description: "Check to run mypy"
      pytest_timeout_minutes:
        type: number
        default: 5
        description: "Timeout for pytest JOB in minutes"

jobs:
  gh_build_image:
    runs-on: [ self-hosted, linux ]
    container:
      # until I found some std image with docker and non-alpline linux for a proper bash/sort/...
      image: "${{ vars.DL_CI_CR_URI }}/datalens_base_ci:latest"
      options: -v /var/run/docker.sock:/var/run/docker.sock
      credentials:
        username: "${{ secrets.DL_CI_CR_USER }}"
        password: "${{ secrets.DL_CI_CR_TOKEN }}"
    steps:
      - name: Log in to the Container registry
        uses: docker/login-action@v2
        with:
          registry: ${{ vars.DL_CI_CR_URI }}
          username: ${{ secrets.DL_CI_CR_USER }}
          password: ${{ secrets.DL_CI_CR_TOKEN }}
      - name: 'Cleanup build folder'
        run: |
          ls -la ./
          rm -rf ./* || true
          rm -rf ./.??* || true
          ls -la ./
      - name: Checkout code
        uses: actions/checkout@v3
      - run: /bin/bash ops/ci/gha_build.sh
        env:
          CR_URI: "${{ vars.DL_CI_CR_URI }}"
          GIT_SHA: "${{ github.sha }}"

  router:
    runs-on: [self-hosted, linux]
    needs: gh_build_image
    container:
      # until https://github.com/github/docs/issues/25520 is resolved, using vars
      image: "${{ vars.DL_CI_CR_URI }}/datalens_ci_with_code:${{ github.sha }}"
      credentials:
        username: "${{ secrets.DL_CI_CR_USER }}"
        password: "${{ secrets.DL_CI_CR_TOKEN }}"
    outputs:
      affected: ${{ steps.get_affected.outputs.affected }}
    steps:
    - name: 'Cleanup build folder'
      run: |
        ls -la ./
        rm -rf ./* || true
        rm -rf ./.??* || true
        ls -la ./
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        fetch-depth: 2
    # https://github.com/actions/runner-images/issues/6775
    - run: git config --global --add safe.directory .
    - name: Get packages affected by changes in the current commit
      # todo: ensure that `git diff  ...` works correctly both for commits and pr requests
      id: get_affected
      # todo: replace diff with: git diff  --name-only  origin/trunk..
      #   after final move to gh repo
      # TARGET=$(git diff --name-only ${{ github.event.after }} ${{ github.event.before }} || echo '')
      #   is not very reliable
      run: |
        . /venv/bin/activate
        TARGET=$(git diff-tree --no-commit-id --name-only --diff-filter=ACMRT -r ${{ github.sha }} || echo '')
        echo "Changed files from git diff: $TARGET"
        detect_affected_packages --repo=$(realpath .) $TARGET
        detect_affected_packages --repo=/data $TARGET >> "$GITHUB_OUTPUT"
      env:
        TEST_TARGET_OVERRIDE: ${{ github.event.inputs.test_targets }}

  pytest_split:
    runs-on: [ self-hosted, linux ]
    needs: router
    container:
      # until https://github.com/github/docs/issues/25520 is resolved, using vars
      image: "${{ vars.DL_CI_CR_URI }}/datalens_ci_with_code:${{ github.sha }}"
      credentials:
        username: "${{ secrets.DL_CI_CR_USER }}"
        password: "${{ secrets.DL_CI_CR_TOKEN }}"
    outputs:
      split: ${{ steps.get_split.outputs.split }}
      split_fat: ${{ steps.get_split.outputs.split_fat }}
    steps:
      - name: 'Cleanup build folder'
        run: |
          ls -la ./
          rm -rf ./* || true
          rm -rf ./.??* || true
          ls -la ./
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 1
      - name: Run python script to split job for general and fat runners
        id: get_split
        run: |
          . /venv/bin/activate && echo '${{ needs.router.outputs.affected }}' >> /tmp/dl_test_targets.json
          export TEST_TARGETS="/tmp/dl_test_targets.json"
          python .github/split_pytest_tasks.py base
          python .github/split_pytest_tasks.py fat
          python .github/split_pytest_tasks.py base >> "$GITHUB_OUTPUT"
          python .github/split_pytest_tasks.py fat >> "$GITHUB_OUTPUT"

  pytest:
    runs-on: [self-hosted, linux, light]
    needs: pytest_split
    if: ${{ needs.pytest_split.outputs.split != '[]' }}
    container:
      image: "${{ vars.DL_CI_CR_URI }}/datalens_ci_with_code:${{ github.sha }}"
      credentials:
        username: "${{ secrets.DL_CI_CR_USER }}"
        password: "${{ secrets.DL_CI_CR_TOKEN }}"
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
    name: "üêç[pytest]${{ matrix.value }}"
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        value: ${{fromJson(needs.pytest_split.outputs.split)}}
    steps:
      - run: mkdir /report
      - run: echo "Running py tests for ${{ matrix.value }}"
      - name: Log in to the Container registry
        uses: docker/login-action@v2
        with:
          registry: ${{ vars.DL_CI_CR_URI }}
          username: ${{ secrets.DL_CI_CR_USER }}
          password: ${{ secrets.DL_CI_CR_TOKEN }}
      - name: 'Cleanup build folder'
        run: |
          ls -la ./
          rm -rf ./* || true
          rm -rf ./.??* || true
          ls -la ./
      - name: Checkout code, just to get access to .github/execute_tests...
        uses: actions/checkout@v3
        with:
          fetch-depth: 1
      - run: echo compose_path="/data/$(echo ${{ matrix.value }} | cut -d ":" -f1)/" >>  "$GITHUB_ENV"
      - run: cd "${{ env.compose_path }}" && echo compose_prj="$(basename "$PWD")_$(shuf -i 1000000-1000000000 -n 1)" >> "$GITHUB_ENV"
      # We need to set custom compose project name to ensure "unique" container names in the host docker env
      - name: run bash script with all logic for starting compose and running tests
        run: bash .github/execute_test_with_docker_compose.sh "${{ matrix.value }}" "${{ job.container.network }}" "${{ env.compose_prj }}"
      - name: Stop compose if provided
        # We could not put this into bash script, since job could be cancelled by user request
        if: always()  # yes! always
        run: bash .github/stop_compose.sh "${{ matrix.value }}" "${{ job.container.network }}"  "${{ env.compose_prj }}"
      - uses: actions/upload-artifact@v3
        if: "!cancelled()"
        with:
          name: "pytest_reports_${{ env.compose_prj }}"
          path: /report/
          retention-days: 1

  pytest_fat:
    # copy-paste, but simpliest solution for now given options provided by github ci
    runs-on: [self-hosted, linux, fat]
    needs: pytest_split
    if: ${{ needs.pytest_split.outputs.split_fat != '[]' }}
    container:
      image: "${{ vars.DL_CI_CR_URI }}/datalens_ci_with_code:${{ github.sha }}"
      credentials:
        username: "${{ secrets.DL_CI_CR_USER }}"
        password: "${{ secrets.DL_CI_CR_TOKEN }}"
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
    name: "üêç[pytest][fat]${{ matrix.value }}"
    timeout-minutes: 60
    strategy:
      fail-fast: false
      matrix:
        value: ${{fromJson(needs.pytest_split.outputs.split_fat)}}
    steps:
      - run: mkdir /report
      - run: echo "Running py tests for ${{ matrix.value }}"
      - run: echo "Split fat ${{ needs.pytest_split.outputs.split_fat }}"
      - name: Log in to the Container registry
        uses: docker/login-action@v2
        with:
          registry: ${{ vars.DL_CI_CR_URI }}
          username: ${{ secrets.DL_CI_CR_USER }}
          password: ${{ secrets.DL_CI_CR_TOKEN }}
      - name: 'Cleanup build folder'
        run: |
          ls -la ./
          rm -rf ./* || true
          rm -rf ./.??* || true
          ls -la ./
      - name: Checkout code, just to get access to .github/execute_tests...
        uses: actions/checkout@v3
        with:
          fetch-depth: 1
      - run: echo compose_path="/data/$(echo ${{ matrix.value }} | cut -d ":" -f1)/" >>  "$GITHUB_ENV"
      - run: cd "${{ env.compose_path }}" && echo compose_prj="$(basename "$PWD")_$(shuf -i 1000000-1000000000 -n 1)" >> "$GITHUB_ENV"
      # We need to set custom compose project name to ensure "unique" container names in the host docker env
      - run: echo "TARGET_PATH=${{ matrix.value }}" "NET_NAME=${{ job.container.network }}" "COMPOSE_PROJECT_NAME=${{ env.compose_prj }}"
      - name: run bash script with all logic for starting compose and running tests
        run: bash .github/execute_test_with_docker_compose.sh "${{ matrix.value }}" "${{ job.container.network }}" "${{ env.compose_prj }}"
      - name: Stop compose if provided
        # We could not put this into bash script, since job could be cancelled by user request
        if: always()  # yes! always
        run: bash .github/stop_compose.sh "${{ matrix.value }}"  "${{ job.container.network }}"  "${{ env.compose_prj }}"
      - uses: actions/upload-artifact@v3
        if: "!cancelled()"
        with:
          name: "pytest_reports_${{ env.compose_prj }}"
          path: /report/
          retention-days: 1

  publish-result:
    runs-on: [self-hosted, linux]
    needs: [ "pytest", "pytest_fat"]
    if: "!cancelled()"
    permissions:
      contents: read
      issues: read
      checks: write
      pull-requests: write
    container: docker:latest
    steps:
      - uses: actions/download-artifact@v3
        with:
          path: ./report/
      - run: ls -lah ./report
      - name: Publish Test Results
        uses: datalens-tech/publish-unit-test-result-action@55478522536e0c60b0a4ff0c2bb8ab110d7a0f33
        with:
          files: |
            ./report/**/*.xml
          event_name: ${{ github.event.workflow_run.event }}
          report_individual_runs: "true"

  mypy:
    runs-on: [ self-hosted, linux ]
    if: ${{ github.event.inputs.run_mypy == 'true' }}
    needs: router
    container:
      # until https://github.com/github/docs/issues/25520 is resolved, using vars
      image: "${{ vars.DL_CI_CR_URI }}/datalens_ci_with_code:${{ github.sha }}"
      credentials:
        username: "${{ secrets.DL_CI_CR_USER }}"
        password: "${{ secrets.DL_CI_CR_TOKEN }}"
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
    name: "üê≤[mypy]${{ matrix.value }}"
    # set more when tuning
    # from json attempt to workaround
    timeout-minutes: ${{ fromJSON(inputs.pytest_timeout_minutes) }}
    strategy:
      fail-fast: false
      matrix:
        value: ${{fromJson(needs.router.outputs.affected)}}
    steps:
      - run: ls "/data/${{ matrix.value }}/"
      - name: run mypy
        run: |
          [ ! -f "/data/${{ matrix.value }}/mypy.ini" ]  &&  (echo "mypy.ini not present, skip") ||  ( cd "/data/${{ matrix.value }}" && TARGET=$(echo ${{ matrix.value }} | cut -d"/" -f2) && . /venv/bin/activate && mypy $TARGET )
        # todo: add script to extract target name from pyproject.toml

# todo:  uncomment when code is linted and being  re-formatted in pre-commit hooks
#  codestyle:
#    runs-on: [self-hosted, linux]
#    needs: wait_for_image
#    container:
#      # until https://github.com/github/docs/issues/25520 is resolved, using vars
#      image: "${{ vars.DL_CI_CR_URI }}/datalens_ci_with_code:${{ github.sha }}"
#      credentials:
#        username: ${{ secrets.DL_CI_CR_USER }}
#        password: ${{ secrets.DL_CI_CR_TOKEN }}
#    steps:
#    - name: Analysing the code with ruff
#      run: . /venv/bin/activate && ruff check lib/ utils/
#    - name: Check style with black
#      run: . /venv/bin/activate && black --check lib/ utils/
